{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b73e7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob as gb\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c752a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+ '/archive/car_data/car_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74eefcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = path+\"/train\"\n",
    "test = path+\"/test\"\n",
    "train_labels = []\n",
    "train_images = []\n",
    "test_labels = []\n",
    "test_images = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "881ea894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path =  [folder for folder in os.listdir(train) if not folder.startswith('.')]\n",
    "test_path =  [folder for folder in os.listdir(test) if not folder.startswith('.')]\n",
    "\n",
    "\n",
    "## get # of photos for train & test\n",
    "train_len = -1\n",
    "for i in os.walk(train, topdown=True):\n",
    "        train_len += len(i[2]) \n",
    "\n",
    "test_len = -1\n",
    "for i in os.walk(test, topdown=True):\n",
    "        test_len += len(i[2]) \n",
    "\n",
    "## add the type of cars into dict\n",
    "d = dict()\n",
    "idx = 0\n",
    "for folder in test_path:\n",
    "    d[folder] = idx\n",
    "    idx+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2bd2e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_name', 'bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get image annotations\n",
    "# Heading names: img_name, bbox_x1, bbox_y1, bbox_x2, bbox_y2, class\n",
    "train_annot = pd.read_csv(os.getcwd() + \"/archive/anno_train.csv\")\n",
    "test_annot = pd.read_csv(os.getcwd() + \"/archive/anno_test.csv\")\n",
    "\n",
    "train_bboxes = []\n",
    "test_bboxes = []\n",
    "\n",
    "train_annot.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aba3cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in test_path:\n",
    "    jpg_path = gb.glob(pathname = test + \"/\" + folder + \"/*.jpg\")\n",
    "    \n",
    "    for img in jpg_path:\n",
    "        img_name = os.path.basename(img)\n",
    "\n",
    "        # Get bounding box value for image\n",
    "        bbox_x1 = test_annot.loc[test_annot['img_name'] == img_name]['bbox_x1']\n",
    "        bbox_y1 = test_annot.loc[test_annot['img_name'] == img_name]['bbox_y1']\n",
    "        bbox_x2 = test_annot.loc[test_annot['img_name'] == img_name]['bbox_x2']\n",
    "        bbox_y2 = test_annot.loc[test_annot['img_name'] == img_name]['bbox_y2']\n",
    "\n",
    "        # Append bounding box value to array\n",
    "        test_bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
    "        \n",
    "        image = cv2.imread(img)\n",
    "        test_labels.append(np.array(d[folder]))\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        test_images.append(np.array(image))\n",
    "\n",
    "for folder in train_path:\n",
    "    jpg_path = gb.glob(pathname = train + \"/\" + folder + \"/*.jpg\")\n",
    "    \n",
    "    for img in jpg_path:\n",
    "        img_name = os.path.basename(img)\n",
    "\n",
    "        # Get bounding box value for image\n",
    "        bbox_x1 = train_annot.loc[train_annot['img_name'] == img_name]['bbox_x1']\n",
    "        bbox_y1 = train_annot.loc[train_annot['img_name'] == img_name]['bbox_y1']\n",
    "        bbox_x2 = train_annot.loc[train_annot['img_name'] == img_name]['bbox_x2']\n",
    "        bbox_y2 = train_annot.loc[train_annot['img_name'] == img_name]['bbox_y2']\n",
    "        \n",
    "        # Append bounding box value to array\n",
    "        train_bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
    "\n",
    "        image = cv2.imread(img)\n",
    "        train_labels.append(np.array(d[folder]))\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        train_images.append(np.array(image))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "947cd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale bounding box to image resolution\n",
    "\n",
    "for i in range(0, len(train_bboxes)):\n",
    "    for j in range(0,4):\n",
    "        train_bboxes[i][j] / 224\n",
    "\n",
    "for i in range(0, len(test_bboxes)):\n",
    "    for j in range(0,4):\n",
    "        test_bboxes[i][j] / 224\n",
    "\n",
    "# Convert from array of pandas series to floats\n",
    "train_bboxes = np.array(train_bboxes, dtype=\"float64\")\n",
    "test_bboxes = np.array(test_bboxes, dtype=\"float64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa1645c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 4, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "256238dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.reshape(train_labels, (-1, 1))\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.reshape(test_labels, (-1, 1))\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "266391f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "(129, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb7dc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images= train_images / 255.0, test_images/ 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a4088c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(224, 224, 3)))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=layers.Input(shape=(224, 224, 3)))\n",
    "\n",
    "model.trainable=True\n",
    "\n",
    "flatten = model.output\n",
    "flatten = layers.Flatten() (flatten)\n",
    "\n",
    "\"\"\"\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5448efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14322380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer header for bounding boxes\n",
    "bbox_output = layers.Dense(128, activation='relu') (flatten)\n",
    "bbox_output = layers.Dense(64, activation='relu') (bbox_output)\n",
    "bbox_output = layers.Dense(32, activation='relu') (bbox_output)\n",
    "bbox_output = layers.Dense(1, activation=\"sigmoid\", name=\"bbox\") (bbox_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aba01eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 512)          12845568    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          3211392     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 512)          0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           8256        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 512)          262656      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 32)           2080        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 512)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " bbox (Dense)                   (None, 1)            33          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " class_label (Dense)            (None, 3)            1539        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,046,212\n",
      "Trainable params: 31,046,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second fully connected layer header for predicting class label\n",
    "label_output = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "label_output = layers.Dropout(0.5) (label_output)\n",
    "label_output = layers.Dense(512, activation=\"relu\") (label_output)\n",
    "label_output = layers.Dropout(0.5) (label_output)\n",
    "label_output = layers.Dense(3, activation=\"softmax\", name=\"class_label\") (label_output)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=(bbox_output, label_output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3529980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in train_path:\n",
    "    jpg_path = gb.glob(pathname = test + \"/\" + folder + \"/*.jpg\")\n",
    "    \n",
    "    for img in jpg_path:\n",
    "        img_name = os.path.basename(img)\n",
    "        image = cv2.imread(img)\n",
    "        np.append(test_labels,np.array(folder))\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        np.append(test_images,np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e287c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set losses for both fully-connected layer headers\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "losses = {\n",
    "    \"class_label\": SparseCategoricalCrossentropy(from_logits=False),\n",
    "    \"bbox\": \"mean_squared_error\"\n",
    "}\n",
    "\n",
    "lossWeights = {\n",
    "    \"class_label\": 1.0,\n",
    "\t\"bbox\": 1.0\n",
    "}\n",
    "\n",
    "# Set targets\n",
    "train_targets = {\n",
    "    \"class_label\": train_labels,\n",
    "    \"bbox\": train_bboxes\n",
    "}\n",
    "\n",
    "test_targets = {\n",
    "    \"class_label\": test_labels,\n",
    "    \"bbox\": test_bboxes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d5198ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 68s 13s/step - loss: 185413.6719 - bbox_loss: 185383.0000 - class_label_loss: 30.6870 - bbox_accuracy: 0.0095 - class_label_accuracy: 0.3130 - val_loss: 182495.2812 - val_bbox_loss: 182494.1719 - val_class_label_loss: 1.1070 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3101\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 63s 13s/step - loss: 185320.1406 - bbox_loss: 185316.6406 - class_label_loss: 3.4845 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.2519 - val_loss: 182495.6562 - val_bbox_loss: 182494.2500 - val_class_label_loss: 1.4167 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3411\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 63s 13s/step - loss: 185318.5469 - bbox_loss: 185316.7188 - class_label_loss: 1.8127 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.3817 - val_loss: 182495.3594 - val_bbox_loss: 182494.1406 - val_class_label_loss: 1.2349 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3488\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 70s 14s/step - loss: 185318.7031 - bbox_loss: 185316.6250 - class_label_loss: 2.0686 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.2595 - val_loss: 182496.7344 - val_bbox_loss: 182495.6406 - val_class_label_loss: 1.1019 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 73s 15s/step - loss: 185318.5625 - bbox_loss: 185316.9844 - class_label_loss: 1.5778 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.3511 - val_loss: 182496.0312 - val_bbox_loss: 182494.1406 - val_class_label_loss: 1.8824 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3488\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 68s 14s/step - loss: 185318.6094 - bbox_loss: 185316.6406 - class_label_loss: 1.9728 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.2901 - val_loss: 182495.2969 - val_bbox_loss: 182494.1406 - val_class_label_loss: 1.1689 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3101\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 71s 14s/step - loss: 185317.8281 - bbox_loss: 185316.6406 - class_label_loss: 1.1915 - bbox_accuracy: 0.0115 - class_label_accuracy: 0.3359 - val_loss: 182495.2344 - val_bbox_loss: 182494.1406 - val_class_label_loss: 1.1037 - val_bbox_accuracy: 0.0116 - val_class_label_accuracy: 0.3566\n",
      "Epoch 8/10\n",
      "2/5 [===========>..................] - ETA: 43s - loss: 220267.9688 - bbox_loss: 220266.7812 - class_label_loss: 1.1819 - bbox_accuracy: 0.0117 - class_label_accuracy: 0.3438"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=losses, loss_weights=lossWeights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_targets, epochs=10,\n",
    "                    validation_data=(test_images, test_targets), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3ee41",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "pred_label = np.argmax(y_pred,axis = 1)\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "def getLabel(i):\n",
    "    return (list(d.keys())[list(d.values()).index(i)])  \n",
    "\n",
    "for i in range(25):\n",
    "    \n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.imshow(test_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.title(\"True: \" + getLabel(test_labels[i][0]) + \"\\n\" + \"Predicted: \" + getLabel(pred_label[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
